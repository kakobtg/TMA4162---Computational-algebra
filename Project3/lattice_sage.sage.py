

# This file was *autogenerated* from the file lattice_sage.sage
from sage.all_cmdline import *   # import sage library

_sage_const_0 = Integer(0); _sage_const_10 = Integer(10); _sage_const_1 = Integer(1); _sage_const_50 = Integer(50); _sage_const_0p75 = RealNumber('0.75'); _sage_const_5 = Integer(5); _sage_const_6 = Integer(6); _sage_const_0p3 = RealNumber('0.3'); _sage_const_2 = Integer(2); _sage_const_4 = Integer(4); _sage_const_8 = Integer(8); _sage_const_16 = Integer(16); _sage_const_20 = Integer(20); _sage_const_32 = Integer(32); _sage_const_15 = Integer(15); _sage_const_3 = Integer(3); _sage_const_1en5 = RealNumber('1e-5')
import time
import matplotlib.pyplot as plt
import numpy as np
from itertools import product
import pandas as pd

# SageMath imports
from sage.all import matrix, vector, random_matrix, ZZ

def gram_schmidt(B):
    return B.gram_schmidt()[_sage_const_0 ]

def babai_rounding_method(B, target):
    G, _ = B.gram_schmidt()
    coeffs = B.solve_left(target)
    rounded_coeffs = vector(ZZ, [round(c) for c in coeffs])
    return B * rounded_coeffs

def shortest_vector_search(B, search_radius=_sage_const_10 ):
    dim = B.ncols()
    min_length = float('inf')
    shortest_vector = None

    for coeffs in product(range(-search_radius, search_radius + _sage_const_1 ), repeat=dim):
        if all(c == _sage_const_0  for c in coeffs):
            continue
        candidate = B * vector(ZZ, coeffs)
        length = candidate.norm()
        if length < min_length:
            min_length = length
            shortest_vector = candidate

    return shortest_vector

def exhaustive_closest_vector_search(B, target, search_radius=_sage_const_50 ):
    best_vector = None
    min_distance = float('inf')

    for coeffs in product(range(-search_radius, search_radius + _sage_const_1 ), repeat=B.ncols()):
        candidate = B * vector(ZZ, coeffs)
        distance = (candidate - target).norm()
        if distance < min_distance:
            min_distance = distance
            best_vector = candidate

    return best_vector

def kannan_embedding(B, target, scale=_sage_const_1 ):
    """Construct Kannan's embedding lattice for solving CVP via SVP."""
    dim = B.ncols()
    augmented_B = B.augment(matrix(ZZ, dim, _sage_const_1 , [_sage_const_0 ] * dim))

    # Convert target vector to integers explicitly
    target_column = vector(ZZ, [round(x) for x in target] + [scale])

    B_prime = augmented_B.stack(target_column)
    return B_prime, scale

def decode_kannan_embedding(short_vector):
    return short_vector[:-_sage_const_1 ]

def lll_reduction(B, delta=_sage_const_0p75 ):
    return B.LLL(delta=delta)

def generate_lattice(dim):
    return random_matrix(ZZ, dim, x=-_sage_const_10 , y=_sage_const_10 )

def generate_bad_target_vector(B):
    coeffs = vector([ZZ.random_element(-_sage_const_5 , _sage_const_6 ) for _ in range(B.ncols())])
    lattice_point = B * coeffs
    offset = vector([_sage_const_0p3 ] * B.nrows())
    return lattice_point + offset

def run_experiment():
    dimensions = [_sage_const_2 , _sage_const_4 , _sage_const_8 , _sage_const_16 , _sage_const_20 , _sage_const_32 ]
    results = []
    babai_times, kannan_times, shortest_times, exhaustive_times = [], [], [], []

    for dim in dimensions:
        print(f"\n--- Running experiment for dimension {dim} ---")
        B = generate_lattice(dim)
        v = generate_bad_target_vector(B)

        start = time.time()
        babai_original = babai_rounding_method(B, v)
        babai_times.append(time.time() - start)

        if dim <= _sage_const_15 :
            start = time.time()
            exhaustive_closest = exhaustive_closest_vector_search(B, v, search_radius=_sage_const_3 )
            exhaustive_times.append(time.time() - start)
        else:
            exhaustive_closest = None
            exhaustive_times.append(None)

        reduced_B = lll_reduction(B)

        start = time.time()
        babai_reduced = babai_rounding_method(reduced_B, v)
        babai_times[-_sage_const_1 ] += time.time() - start

        start = time.time()
        B_prime, scale = kannan_embedding(reduced_B, v)
        kannan_short_vector = babai_rounding_method(B_prime, vector(v.list() + [scale]))
        kannan_closest_decoded = decode_kannan_embedding(kannan_short_vector)
        kannan_times.append(time.time() - start)

        start = time.time()
        shortest_original = shortest_vector_search(B, search_radius=_sage_const_3 )
        shortest_reduced = shortest_vector_search(reduced_B, search_radius=_sage_const_3 )
        shortest_times.append(time.time() - start)

        babai_kannan_match = (babai_original - kannan_closest_decoded).norm() < _sage_const_1en5 
        babai_correct = exhaustive_closest is None or (babai_original - exhaustive_closest).norm() < _sage_const_1en5 
        kannan_correct = exhaustive_closest is None or (kannan_closest_decoded - exhaustive_closest).norm() < _sage_const_1en5 
        
        results.append({
            "Dim": dim,
            "Babai Error (Original)": (babai_original - v).norm(),
            "Babai Error (Reduced)": (babai_reduced - v).norm(),
            "Kannan Error": (kannan_closest_decoded - v).norm(),
            "Babai-Kannan Match": babai_kannan_match,
            "Shortest Norm (Original)": shortest_original.norm() if shortest_original else None,
            "Shortest Norm (Reduced)": shortest_reduced.norm() if shortest_reduced else None,
            "Babai Correct?": babai_correct,
            "Kannan Correct?": kannan_correct
        })

        print(f"Dimension {dim} completed.\n")

    df = pd.DataFrame(results)
    print("\nFinal Results:")
    print(df.to_string(index=False))

    plt.plot(dimensions, babai_times, label='Babai Rounding Method', marker='o')
    plt.plot([d for d in dimensions if d <= _sage_const_8 ], [t for t in exhaustive_times if t is not None], label='Exhaustive Search', marker='x')
    plt.plot(dimensions, kannan_times, label='Kannan Embedding Method', marker='s')
    plt.plot([d for d in dimensions if d <= _sage_const_8 ], [t for t in shortest_times if t is not None], label='Shortest Vector Search', marker='d')
    plt.yscale('log')
    plt.xlabel('Lattice Dimension')
    plt.ylabel('Runtime (seconds)')
    plt.legend()
    plt.title('Runtime Comparison of Closest and Shortest Vector Algorithms')
    plt.show()

run_experiment()

